{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import music21 as m21\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SONGS_PATH = \"Data/erk\"\n",
    "ACCEPTABLE_DURATIONS = [0.25, 0.5, 0.75, 1.0, 1.5, 2, 3, 4]\n",
    "SAVE = \"Dataset\"\n",
    "SINGLE_FILE_PATH = \"single_file\"\n",
    "LENGTH = 64\n",
    "DICT_PATH = \"dict.json\"\n",
    "\n",
    "def load_songs(datset_path):\n",
    "    songsList = []\n",
    "    for path,subdir,files in os.walk(datset_path):\n",
    "        for file in files:\n",
    "            if file[-3:] == \"krn\":\n",
    "                songsList.append(m21.converter.parse(os.path.join(path, file)))\n",
    "    return songsList\n",
    "\n",
    "def filter_durations(song, ACCEPTABLE_DURATIONS):\n",
    "\n",
    "    for note in song.flat.notesAndRests:\n",
    "        if note.duration.quarterLength not in ACCEPTABLE_DURATIONS:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Changing the music data to time series representation\n",
    "def encode_song(song, timeStamp = 0.25):\n",
    "\n",
    "    encoded_list = []\n",
    "    for event in song.flat.notesAndRests:\n",
    "\n",
    "        if isinstance (event, m21.note.Note):\n",
    "            symbol = event.pitch.midi\n",
    "        \n",
    "        if isinstance(event, m21.note.Rest):\n",
    "            symbol = \"r\"\n",
    "    \n",
    "        steps = int(event.duration.quarterLength / timeStamp)\n",
    "        for step in range(steps):\n",
    "            if step == 0:\n",
    "                encoded_list.append(symbol)\n",
    "            else:\n",
    "                encoded_list.append(\"_\")\n",
    "\n",
    "    encoded_list = \" \".join(map(str, encoded_list))\n",
    "    return encoded_list\n",
    "\n",
    "\n",
    "def transpose(song):\n",
    "\n",
    "    # music score has multiple parts\n",
    "    parts = song.getElementsByClass(m21.stream.Part)\n",
    "    partZero = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "    key = partZero[0][4]\n",
    "\n",
    "    # Estimating key incase there isn't one\n",
    "    if not isinstance(key, m21.key.Key):\n",
    "        key = song.analyze(\"key\")\n",
    "    \n",
    "    # Interval for transposition\n",
    "    if key.mode == \"major\":\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
    "    elif key.mode == 'minor':\n",
    "        interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
    "    \n",
    "    transpose_song = song.transpose(interval)\n",
    "    return transpose_song\n",
    "    \n",
    "    \n",
    "def preprocess(dataset_path):\n",
    "    songs = load_songs(dataset_path)\n",
    "    print(f\"# songs loaded = {len(songs)}\")\n",
    "    \n",
    "    for i, song in enumerate(songs):\n",
    "\n",
    "        # Filtering durations\n",
    "        if not filter_durations(song, ACCEPTABLE_DURATIONS):\n",
    "            continue\n",
    "        \n",
    "        # Transpoing to C maj / A min\n",
    "        song = transpose(song)\n",
    "\n",
    "         # Encoding\n",
    "        encoded_song = encode_song(song)\n",
    "\n",
    "        SAVE_songs = os.path.join(SAVE, str(i))\n",
    "        with open(SAVE_songs, \"w\") as fp:\n",
    "            fp.write(encoded_song)\n",
    "    \n",
    "def load(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        song = fp.read()\n",
    "        return song\n",
    "\n",
    "def create_single_file(dataset_path, file_path, sequence_len):\n",
    "    delimeter = \"/ \" * sequence_len\n",
    "    songs = \"\"\n",
    "\n",
    "# Adding delimeters after loading the encoded songs\n",
    "    for path, subdir, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            filePath = os.path.join(path, file)\n",
    "            song = load(filePath)\n",
    "            songs = songs + song + \" \" + delimeter\n",
    "    # Take everything apart from the last character which is a space\n",
    "    songs = songs[:-1]\n",
    "\n",
    "    with open(file_path, \"w\") as fp:\n",
    "        fp.write(songs)\n",
    "    \n",
    "    return songs\n",
    "\n",
    "def mapping(songs, dict_path):\n",
    "    \n",
    "    dict = {}\n",
    "\n",
    "    songs = songs.split()\n",
    "    uniqueValues = list(set(songs))\n",
    "\n",
    "    for i, el in enumerate(uniqueValues):\n",
    "        dict[el] = i\n",
    "    \n",
    "    with open(dict_path, \"w\") as fp:\n",
    "        json.dump(dict, fp, indent=2)\n",
    "\n",
    "# Converting the song to a list of integers\n",
    "def convert_songs(songs):\n",
    "\n",
    "    intList = []    \n",
    "\n",
    "    # Mapping List\n",
    "    with open(DICT_PATH, \"r\") as fp:\n",
    "        dict = json.load(fp)\n",
    "    \n",
    "    # Converting string to list\n",
    "    songs = songs.split()\n",
    "\n",
    "    # Mapping every symbol in the songs list to int\n",
    "    for el in songs:\n",
    "        intList.append(dict[el])\n",
    "    \n",
    "    return intList\n",
    "\n",
    "# Generating training sequences, which are a subsets of time series music representation\n",
    "def training_sequence(sequence_length):\n",
    "    \n",
    "    songs = load(SINGLE_FILE_PATH)\n",
    "    mapped_songs = convert_songs(songs)\n",
    "\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    # Generating sequences\n",
    "    # Predicting the next musical event in the melody\n",
    "    # 64 time steps for each training sample\n",
    "    total_sequences = len(mapped_songs) - sequence_length\n",
    "    for i in range(total_sequences):\n",
    "        # Ex: [1,2,3,4] [i: [1,2] -> t: [3]] [[2,3] -> [4]] \n",
    "        inputs.append(mapped_songs[i:i+sequence_length])\n",
    "        targets.append(mapped_songs[i+sequence_length])\n",
    "    \n",
    "    # One Hot Ecnoding\n",
    "    # Inputs is a 2D array, (total_sequences, sequence_length, unique_elements)\n",
    "    # [[0,1,2],[1,1,2]] -> [[[1,0,0], [0,1,0], [0,0,1]], []]\n",
    "    #                           0         1        2\n",
    "    unique_elements = len(set(mapped_songs))\n",
    "    inputs = keras.utils.to_categorical(inputs, num_classes=unique_elements)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     preprocess(SONGS_PATH)\n",
    "#     songs = create_single_file(SAVE, SINGLE_FILE_PATH,  LENGTH)\n",
    "#     mapping(songs, DICT_PATH)\n",
    "#     inputs, targets = training_sequence(LENGTH)\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_UNITS = 38 # Total number of unique symbols\n",
    "NUM_UNITS = [256] # Number of units in the internal layer and this case there is only one layer\n",
    "LOSS = \"sparse_categorical_crossentropy\" # Loss function\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64 # Amount of samples that the network is gonna see before running back propogation\n",
    "SAVE_NETWORK_PATH = \"Network_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(output_units, num_units, loss, learning_rate):\n",
    "    \n",
    "    # Model architecture\n",
    "    input_layer = keras.layers.Input(shape=(None, output_units))\n",
    "    x = keras.layers.LSTM(num_units[0])(input_layer)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    output_layer = keras.layers.Dense(output_units, activation = \"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(input_layer, output_layer)\n",
    "    \n",
    "    # Compiling Model\n",
    "    model.compile(loss=loss, \n",
    "                optimizer=keras.optimizers.Adam(lr = learning_rate), \n",
    "                metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None, 38)]        0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               302080    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                9766      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 311,846\n",
      "Trainable params: 311,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sb/tensorflow-test/env/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 11:11:56.941395: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-06 11:11:58.096527: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 11:11:58.354632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-06 11:12:01.008455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5660/5660 [==============================] - 168s 29ms/step - loss: 0.6740 - accuracy: 0.7913\n",
      "Epoch 2/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.5661 - accuracy: 0.8170\n",
      "Epoch 3/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.5282 - accuracy: 0.8291\n",
      "Epoch 4/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.5002 - accuracy: 0.8370\n",
      "Epoch 5/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.4796 - accuracy: 0.8431\n",
      "Epoch 6/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.4621 - accuracy: 0.8483\n",
      "Epoch 7/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.4468 - accuracy: 0.8529\n",
      "Epoch 8/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.4308 - accuracy: 0.8579\n",
      "Epoch 9/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.4192 - accuracy: 0.8613\n",
      "Epoch 10/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.4031 - accuracy: 0.8663\n",
      "Epoch 11/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.3920 - accuracy: 0.8699\n",
      "Epoch 12/50\n",
      "5660/5660 [==============================] - 170s 30ms/step - loss: 0.3803 - accuracy: 0.8735\n",
      "Epoch 13/50\n",
      "5660/5660 [==============================] - 176s 31ms/step - loss: 0.3691 - accuracy: 0.8773\n",
      "Epoch 14/50\n",
      "5660/5660 [==============================] - 175s 31ms/step - loss: 0.3574 - accuracy: 0.8804\n",
      "Epoch 15/50\n",
      "5660/5660 [==============================] - 177s 31ms/step - loss: 0.3512 - accuracy: 0.8824\n",
      "Epoch 16/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.3414 - accuracy: 0.8855\n",
      "Epoch 17/50\n",
      "5660/5660 [==============================] - 167s 30ms/step - loss: 0.3330 - accuracy: 0.8885\n",
      "Epoch 18/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.3260 - accuracy: 0.8902\n",
      "Epoch 19/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.3181 - accuracy: 0.8926\n",
      "Epoch 20/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.3119 - accuracy: 0.8947\n",
      "Epoch 21/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.3065 - accuracy: 0.8966\n",
      "Epoch 22/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.3024 - accuracy: 0.8976\n",
      "Epoch 23/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.2963 - accuracy: 0.8998\n",
      "Epoch 24/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.2913 - accuracy: 0.9010\n",
      "Epoch 25/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.2864 - accuracy: 0.9031\n",
      "Epoch 26/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.2846 - accuracy: 0.9033\n",
      "Epoch 27/50\n",
      "5660/5660 [==============================] - 169s 30ms/step - loss: 0.2787 - accuracy: 0.9056\n",
      "Epoch 28/50\n",
      "5660/5660 [==============================] - 167s 29ms/step - loss: 0.2697 - accuracy: 0.9085\n",
      "Epoch 29/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2701 - accuracy: 0.9080\n",
      "Epoch 30/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2708 - accuracy: 0.9080\n",
      "Epoch 31/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2753 - accuracy: 0.9059\n",
      "Epoch 32/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.3244 - accuracy: 0.8919\n",
      "Epoch 33/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.3026 - accuracy: 0.8975\n",
      "Epoch 34/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.2984 - accuracy: 0.8983\n",
      "Epoch 35/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.3013 - accuracy: 0.8977\n",
      "Epoch 36/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2855 - accuracy: 0.9029\n",
      "Epoch 37/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2797 - accuracy: 0.9047\n",
      "Epoch 38/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.2727 - accuracy: 0.9070\n",
      "Epoch 39/50\n",
      "5660/5660 [==============================] - 166s 29ms/step - loss: 0.2714 - accuracy: 0.9072\n",
      "Epoch 40/50\n",
      "5660/5660 [==============================] - 165s 29ms/step - loss: 0.2619 - accuracy: 0.9109\n",
      "Epoch 41/50\n",
      "5660/5660 [==============================] - 167s 30ms/step - loss: 0.2602 - accuracy: 0.9109\n",
      "Epoch 42/50\n",
      "5660/5660 [==============================] - 168s 30ms/step - loss: 0.2580 - accuracy: 0.9117\n",
      "Epoch 43/50\n",
      "5660/5660 [==============================] - 167s 30ms/step - loss: 0.2520 - accuracy: 0.9140\n",
      "Epoch 44/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.2483 - accuracy: 0.9153\n",
      "Epoch 45/50\n",
      "5660/5660 [==============================] - 164s 29ms/step - loss: 0.2446 - accuracy: 0.9162\n",
      "Epoch 46/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.2434 - accuracy: 0.9170\n",
      "Epoch 47/50\n",
      "5660/5660 [==============================] - 162s 29ms/step - loss: 0.2384 - accuracy: 0.9179\n",
      "Epoch 48/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.2344 - accuracy: 0.9193\n",
      "Epoch 49/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.2335 - accuracy: 0.9202\n",
      "Epoch 50/50\n",
      "5660/5660 [==============================] - 163s 29ms/step - loss: 0.2297 - accuracy: 0.9206\n"
     ]
    }
   ],
   "source": [
    "def train(ouput_units = OUTPUT_UNITS, num_units = NUM_UNITS, loss = LOSS, learning_rate = LEARNING_RATE):\n",
    "     # Generating training sequences\n",
    "     inputs, targets =  training_sequence(LENGTH)\n",
    "\n",
    "     # Neural Network\n",
    "     network = build_network(ouput_units, num_units, loss, learning_rate)\n",
    "\n",
    "     # Training the network\n",
    "     network.fit(inputs, targets, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "     network.save(SAVE_NETWORK_PATH)\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27ec4398efe5f1e0762e95a3ab8e2cbf2dfb129f4bce910de35277a628037a44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
